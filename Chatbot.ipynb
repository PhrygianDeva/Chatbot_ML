{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNhMqlz3w/G0TqnPa4mh2Nh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PhrygianDeva/Chatbot_ML/blob/master/Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vri42fQ7VKKI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import json\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense , Embedding , GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/intents.json') as file:\n",
        "  data = json.load(file)\n",
        "\n",
        "training_sentences=[]\n",
        "training_labels=[]\n",
        "labels=[]\n",
        "responses=[]\n",
        "\n",
        "for intent in data['intents']:\n",
        "  for pattern in intent['patterns']:\n",
        "    training_sentences.append(pattern)\n",
        "    training_labels.append(intent['tag'])\n",
        "  responses.append(intent['responses'])\n",
        "\n",
        "  if intent['tag'] not in labels:\n",
        "    labels.append(intent['tag'])\n",
        "\n",
        "  num_classes=len(labels)\n",
        "\n",
        "num_classes"
      ],
      "metadata": {
        "id": "uaU04XMSV5St",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36860e25-eb2d-49a8-c111-0a369102f9ad"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lbl_encoder = LabelEncoder()\n",
        "lbl_encoder.fit(training_labels)\n",
        "\n",
        "training_labels=lbl_encoder.transform(training_labels)\n"
      ],
      "metadata": {
        "id": "0gMpfcIDH0My"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 1000\n",
        "embedding_dim=16\n",
        "max_len=20\n",
        "oov_token=\"<00V>\"\n",
        "\n",
        "tokenizer=Tokenizer(num_words=vocab_size,oov_token=oov_token)\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "word_index=tokenizer.word_index\n",
        "\n",
        "sequences=tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_sequences=pad_sequences(sequences,truncating=\"post\",maxlen=max_len)\n"
      ],
      "metadata": {
        "id": "8Nu9x1PuISlT"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "\n",
        "model.add(Embedding(vocab_size,embedding_dim,input_length=max_len))\n",
        "\n",
        "model.add(GlobalAveragePooling1D())\n",
        "\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(num_classes,activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam' , metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "epochs=20\n",
        "history = model.fit(padded_sequences,np.array(training_labels),epochs=epochs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEL3BYkGtgUg",
        "outputId": "f3e74483-5062-4584-aff6-884dba98a087"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 20, 16)            16000     \n",
            "                                                                 \n",
            " global_average_pooling1d_4  (None, 16)                0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 16)                272       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16408 (64.09 KB)\n",
            "Trainable params: 16408 (64.09 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 1s 8ms/step - loss: 2.0782 - accuracy: 0.1212\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.0769 - accuracy: 0.1212\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0766 - accuracy: 0.1212\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0760 - accuracy: 0.1212\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0752 - accuracy: 0.1212\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0745 - accuracy: 0.2424\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0738 - accuracy: 0.2727\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0732 - accuracy: 0.2424\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0728 - accuracy: 0.2424\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0723 - accuracy: 0.2424\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0718 - accuracy: 0.2424\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0714 - accuracy: 0.3030\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0709 - accuracy: 0.3333\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0705 - accuracy: 0.3333\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0702 - accuracy: 0.3030\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0699 - accuracy: 0.2727\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0697 - accuracy: 0.2121\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0694 - accuracy: 0.2121\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0690 - accuracy: 0.2121\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0683 - accuracy: 0.2727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"chat\")\n",
        "\n",
        "import pickle\n",
        "\n",
        "with open('tokenizer.pickle' , 'wb') as handle:\n",
        "  pickle.dump(tokenizer,handle,protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "with open('label_encoder.pickle','wb') as ecn_file:\n",
        "  pickle.dump(lbl_encoder,ecn_file,protocol=pickle.HIGHEST_PROTOCOL)\n",
        ""
      ],
      "metadata": {
        "id": "EJ_mZ9MDxjK-"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colorama\n",
        "import colorama\n",
        "\n",
        "colorama.init()\n",
        "\n",
        "from colorama import Fore, Style , Back\n",
        "\n",
        "import random"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cctnkGMypWJ",
        "outputId": "fd501b27-b472-4290-9866-8e01e26bcc3c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/intents.json') as file:\n",
        "  data=json.load(file)\n",
        "\n",
        "def chat():\n",
        "  model=keras.models.load_model('chat')\n",
        "\n",
        "  with open('tokenizer.pickle','rb') as handle:\n",
        "    tokenizer=pickle.load(handle)\n",
        "\n",
        "  with open('label_encoder.pickle','rb') as enc:\n",
        "    lbl_encoder=pickle.load(enc)\n",
        "\n",
        "    max_len=20\n",
        "\n",
        "  while True:\n",
        "    print(Fore.LIGHTBLUE_EX + \"User:\" + Style.RESET_ALL,end=\"\")\n",
        "    inp=input()\n",
        "    if inp.lower()==\"quit\":\n",
        "      break\n",
        "\n",
        "    result=model.predict(keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([inp]),\n",
        "                                                                    truncating='post',maxlen=max_len))\n",
        "\n",
        "    tag = lbl_encoder.inverse_transform([np.argmax(result)])\n",
        "\n",
        "    for i in data['intents']:\n",
        "      if i['tag']==tag:\n",
        "        print(Fore.GREEN+ \"ChatBot:\" + Style.RESET_ALL,np.random.choice(i['responses']))\n",
        "\n",
        "print(Fore.YELLOW+ \"Start message\" + Style.RESET_ALL)\n",
        "\n",
        "chat()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5d2zsdZzStN",
        "outputId": "2b6038df-f9ad-4c2e-fd0d-90fe3c87aa06"
      },
      "execution_count": 29,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start message\n",
            "User:Hi\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "ChatBot: Hi\n",
            "User:yay\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "ChatBot: Hi\n",
            "User:ke\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "ChatBot: Hi there\n",
            "User:thank you\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "ChatBot: Hi\n",
            "User:Hey\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "ChatBot: Hi there\n",
            "User:Help me\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "ChatBot: Hi\n",
            "User:Could you help me?\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "ChatBot: Hi\n",
            "User:quit\n"
          ]
        }
      ]
    }
  ]
}